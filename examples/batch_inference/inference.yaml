envs:
  DATA_BUCKET: r2://skypilot-lmsys-chat-1m
  # DATA_BUCKET: s3://skypilot-lmsys-chat-1m/
  # The name of the model to be used for inference.
  MODEL_NAME: meta-llama/Meta-Llama-3.1-8B-Instruct
  HF_TOKEN:


file_mounts:
  /data:
    source: $DATA_BUCKET
    mode: MOUNT

workdir: .

resources:
  accelerators: L4:1

setup: |
  pip install vllm


run: |
  python inference.py \
    --model-name $MODEL_NAME \
    --data-chunk /data/part_0.jsonl \
    --num-gpus $SKYPILOT_NUM_GPUS_PER_NODE
